#sidebar Jython_TableOfContents
= Chunking =
*Table of contents*
<wiki:toc max_depth="3" />

== Introduction ==

Chunking (or shallow parsing) divides a sentence into its constituents like noun groups, verb groups, etc. However, it does not specify their internal structure nor their role in the sentence.

== !OpenNlpChunker ==

The _!OpenNlpChunker_ can be used straight forward. The following script depicts the usage of this chunker.

{{{
#!/usr/bin/env jython
# Filename: chunking.jy
"""
Reads in a specific text file and chunks the input text
Run by: jython chunking.jy <filename> <language-code>
"""


# Fix classpath scanning - otherise uimaFIT will not find the UIMA types
from java.lang import Thread
from org.python.core.imp import *
Thread.currentThread().contextClassLoader = getSyspathJavaLoader()

# Dependencies and imports for DKPro modules
from jip.embed import require

# Text Reader
require('de.tudarmstadt.ukp.dkpro.core:de.tudarmstadt.ukp.dkpro.core.io.text-asl:1.6.2')
from de.tudarmstadt.ukp.dkpro.core.io.text import *

# OpenNlp
require('de.tudarmstadt.ukp.dkpro.core:de.tudarmstadt.ukp.dkpro.core.opennlp-asl:1.6.2')
from de.tudarmstadt.ukp.dkpro.core.opennlp import *


# Dependencies for selecting specific annotations like sentences/tokens
from de.tudarmstadt.ukp.dkpro.core.api.segmentation.type import * #Token, Sentence, Stem, Lemma
from de.tudarmstadt.ukp.dkpro.core.api.syntax.type.chunk import * #Chunk

# uimaFIT imports
from org.apache.uima.fit.util.JCasUtil import *
from org.apache.uima.fit.pipeline.SimplePipeline import *
from org.apache.uima.fit.factory.CollectionReaderFactory import *
from org.apache.uima.fit.factory.AnalysisEngineFactory import *


# Access to commandline arguments
import sys

# Check that all necessary arguments have been passed to the program
if len(sys.argv) < 3:
    print globals()['__doc__'] % locals()
    sys.exit(1)



# Assemble and run pipeline
pipeline = iteratePipeline(
  createReaderDescription(TextReader,
    TextReader.PARAM_PATH, sys.argv[1],
    TextReader.PARAM_LANGUAGE, sys.argv[2],
     ),
  createEngineDescription(OpenNlpSegmenter),
  createEngineDescription(OpenNlpPosTagger),
  createEngineDescription(OpenNlpChunker));

for jcas in pipeline:
    print "Chunks:"
    for chunk in select(jcas, Chunk):
        print chunk.coveredText+"\t"+chunk.chunkValue

}}}

You can execute this script by calling:
{{{
jython chunking.jy examples/example-en.txt en
}}}

== !TreeTagger Chunker ==
Due to copyright reasons, the !TreeTagger chunker cannot be directly downloaded from our repository. Instead, we must first download it from the !TreeTagger website and point DKPro to the location of !TreeTagger.

See [Jython_Preprocessing_POS#TreeTagger Part-of-Speech Tagging with TreeTagger] for further information on the setup. Also make sure to download the corresponding chunking model from the !TreeTagger website and place it in the same folder as `chunking_treetagger.jy` (or alternatively, update the value for `PARAM_MODEL_PATH`).

The following script first runs TreeTagger to determine the POS-tags and then to derive the chunks. Note, in case you execute this script under Windows, you need to change the parameter for the !TreeTaggerPosLemmaTT4J and !TreeTaggerChunkerTT4J to `tree-tagger.exe`.

{{{
#!/usr/bin/env jython
# Filename: chunking_treetagger.jy
"""
Reads in a specific text file and runs first the OpenNlpSegmenter and then the TreeTagger for POS-tagging and chunking.
Run by: jython chunking_treetagger.jy <filename> <language-code>
"""

# Fix classpath scanning - otherise uimaFIT will not find the UIMA types
from java.lang import Thread
from org.python.core.imp import *
Thread.currentThread().contextClassLoader = getSyspathJavaLoader()

# Dependencies and imports for DKPro modules
from jip.embed import require

# OpenNLP 
require('de.tudarmstadt.ukp.dkpro.core:de.tudarmstadt.ukp.dkpro.core.opennlp-asl:1.6.2')
from de.tudarmstadt.ukp.dkpro.core.opennlp import *

# TreeTagger
require('de.tudarmstadt.ukp.dkpro.core:de.tudarmstadt.ukp.dkpro.core.treetagger-asl:1.6.2')
from de.tudarmstadt.ukp.dkpro.core.treetagger import *

# TextReader
require('de.tudarmstadt.ukp.dkpro.core:de.tudarmstadt.ukp.dkpro.core.io.text-asl:1.6.2')
from de.tudarmstadt.ukp.dkpro.core.io.text import *

# Dependencies for selecting specific annotations like sentences/tokens
from de.tudarmstadt.ukp.dkpro.core.api.segmentation.type import * #Token, Sentence, Stem, Lemma
from de.tudarmstadt.ukp.dkpro.core.api.syntax.type.chunk import * #Chunk

# uimaFIT imports
from org.apache.uima.fit.util.JCasUtil import *
from org.apache.uima.fit.pipeline.SimplePipeline import *
from org.apache.uima.fit.factory.CollectionReaderFactory import *
from org.apache.uima.fit.factory.AnalysisEngineFactory import *

# Access to commandline arguments
import sys

# Check that all necessary arguments have been passed to the program
if len(sys.argv) < 3:
    print globals()['__doc__'] % locals()
    sys.exit(1)


# Assemble and run pipeline
pipeline = iteratePipeline(
  createReaderDescription(TextReader,
    TextReader.PARAM_PATH, sys.argv[1],
    TextReader.PARAM_LANGUAGE, sys.argv[2]),
  createEngineDescription(OpenNlpSegmenter),
  createEngineDescription(TreeTaggerPosLemmaTT4J,
    TreeTaggerPosLemmaTT4J.PARAM_EXECUTABLE_PATH, "tree-tagger", #!! Change to "tree-tagger.exe" if the script is executed under windows !!
    TreeTaggerPosLemmaTT4J.PARAM_MODEL_PATH, "german-par-linux-3.2-utf8.bin",
    TreeTaggerPosLemmaTT4J.PARAM_MODEL_ENCODING, "UTF-8"),
  createEngineDescription(TreeTaggerChunkerTT4J,
    TreeTaggerChunkerTT4J.PARAM_EXECUTABLE_PATH, "tree-tagger", #!! Change to "tree-tagger.exe" if the script is executed under windows !!
    TreeTaggerChunkerTT4J.PARAM_MODEL_PATH, "german-chunker-utf8.par",
    TreeTaggerChunkerTT4J.PARAM_MODEL_ENCODING, "UTF-8"));


for jcas in pipeline:
    print "Token\tPOS\tLemma"
    for token in select(jcas, Token):
        print token.coveredText + "\t" + token.pos.posValue + "\t" + token.lemma.value
    
    print "\n\nChunk\tChunk Value"
    for chunk in select(jcas, Chunk):
        print chunk.coveredText + "\t" + chunk.chunkValue
}}}

You can execute this script by calling: 
{{{
jython chunking_treetagger.jy examples/example-de.txt de
}}}