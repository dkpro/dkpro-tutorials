#!/usr/bin/env jython
"""
Reads in a specific text file and prints a parse tree following the conventions of Penn TreeBank
Run by: jython parsing_dependency.jy <filename> <language-code>
"""


# Fix classpath scanning - otherise uimaFIT will not find the UIMA types
from java.lang import Thread
from org.python.core.imp import *
Thread.currentThread().contextClassLoader = getSyspathJavaLoader()

from java.lang import Exception
from java.lang import OutOfMemoryError

# Dependencies and imports for DKPro modules
from jip.embed import require

# Text Reader
require('de.tudarmstadt.ukp.dkpro.core:de.tudarmstadt.ukp.dkpro.core.io.text-asl:1.6.2')
from de.tudarmstadt.ukp.dkpro.core.io.text import *

# OpenNlp
require('de.tudarmstadt.ukp.dkpro.core:de.tudarmstadt.ukp.dkpro.core.opennlp-asl:1.6.2')
from de.tudarmstadt.ukp.dkpro.core.opennlp import *

# ClearNlp
require('de.tudarmstadt.ukp.dkpro.core:de.tudarmstadt.ukp.dkpro.core.clearnlp-asl:1.6.2')
from de.tudarmstadt.ukp.dkpro.core.clearnlp import *

# MaltParser
require('de.tudarmstadt.ukp.dkpro.core:de.tudarmstadt.ukp.dkpro.core.maltparser-asl:1.6.2')
from de.tudarmstadt.ukp.dkpro.core.maltparser import *

# MateTools
require('de.tudarmstadt.ukp.dkpro.core:de.tudarmstadt.ukp.dkpro.core.matetools-gpl:1.6.2')
from de.tudarmstadt.ukp.dkpro.core.matetools import *


# Dependencies for selecting specific annotations like sentences/tokens
from de.tudarmstadt.ukp.dkpro.core.api.segmentation.type import * #Token, Sentence, Stem, Lemma
from de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency import * #Dependency


# uimaFIT imports
from org.apache.uima.fit.util.JCasUtil import *
from org.apache.uima.fit.pipeline.SimplePipeline import *
from org.apache.uima.fit.factory.CollectionReaderFactory import *
from org.apache.uima.fit.factory.AnalysisEngineFactory import *


# Access to commandline arguments
import sys

# Check that all necessary arguments have been passed to the program
if len(sys.argv) < 3:
    print globals()['__doc__'] % locals()
    sys.exit(1)
    
# Function to print the parser output
def printDependencyOutput(name, pipeline):
    print "\n\n%s:" % name
    print "Token\tDependency Type\tGovernor"
    for jcas in pipeline:
        for token in select(jcas, Token):
            dependencyAnnotations = selectCovered(Dependency, token)
            depend = dependencyAnnotations[0] if len(dependencyAnnotations) > 0 else None
            dependencyType = depend.dependencyType if depend != None else "-"
            governorText = depend.getGovernor().coveredText if depend != None else "-"
            print "%s\t%s\t%s" % (token.coveredText, dependencyType, governorText)

# Our text reader which we use for all parser
reader = createReaderDescription(TextReader,
    TextReader.PARAM_PATH, sys.argv[1],
    TextReader.PARAM_LANGUAGE, sys.argv[2],
     )


# Run ClearNlpDependencyParser
try:
    pipeline = iteratePipeline(
          reader,
          createEngineDescription(ClearNlpSegmenter),
          createEngineDescription(ClearNlpPosTagger),
          createEngineDescription(ClearNlpLemmatizer),
          createEngineDescription(ClearNlpDependencyParser)
        );
        
    printDependencyOutput("ClearNlpDependencyParser", pipeline)
except OutOfMemoryError:
    print 'ClearNlpDependencyParser out of memory'
except:
    print 'ClearNlpDependencyParser is not working'
    
 
# Run MaltParser
try:
    pipeline = iteratePipeline(
          reader,
          createEngineDescription(OpenNlpSegmenter),
          createEngineDescription(OpenNlpPosTagger),
          createEngineDescription(MaltParser)
        );
        
    printDependencyOutput("MaltParser", pipeline)
except OutOfMemoryError:
    print 'MaltParser out of memory'
except:
    print 'MaltParser is not working'


# Run MateParser
try:
    pipeline = iteratePipeline(
          reader,
          createEngineDescription(OpenNlpSegmenter),
          createEngineDescription(MatePosTagger),
          createEngineDescription(MateParser)
        );
        
    printDependencyOutput("MateParser", pipeline)
except OutOfMemoryError:
    print 'MateParser out of memory'
except:
    print 'MateParser is not working'
    

